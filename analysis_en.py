# teacher_analyzer_app.py
import streamlit as st
import os
import tempfile
from transformers import pipeline
from PyPDF2 import PdfReader
import pytesseract
from PIL import Image
import io

st.set_page_config(page_title="Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ù„Ù…Ø© Ø§Ù„Ø°ÙƒÙŠ", layout="centered")
st.title("ğŸ“š Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ù„Ù…Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©")

uploaded_file = st.file_uploader("ğŸ“ Ø­Ù…Ù‘Ù„ÙŠ Ù…Ù„Ù Ø§Ù„Ø¯Ø±Ø³ (PDF, ØµÙˆØ±Ø©)", type=["pdf", "jpg", "png"])

# ---------- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ ----------
def extract_text_from_pdf(file):
    reader = PdfReader(file)
    return "\n".join(page.extract_text() for page in reader.pages if page.extract_text())

def extract_text_from_image(image_file):
    image = Image.open(image_file)
    return pytesseract.image_to_string(image, lang='ara')

# ---------- ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ----------
def generate_questions(text):
    qa_pipeline = pipeline("text2text-generation", model="google/flan-t5-base")
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙÙ‚Ø±Ø§Øª Ø£Ùˆ Ø¬Ù…Ù„ Ø·ÙˆÙŠÙ„Ø© ÙˆØªÙˆÙ„ÙŠØ¯ Ø£ÙƒØ«Ø± Ù…Ù† Ø³Ø¤Ø§Ù„ Ù„ÙƒÙ„ Ø¬Ø²Ø¡
    chunks = [text[i:i+500] for i in range(0, len(text), 500)]
    all_questions = []

    for chunk in chunks:
        prompt = (
            f"Generate 2 to 3 different comprehension questions in English from the following lesson text. "
            f"Do not include answers, and separate questions by newline:\n\n{chunk}"
        )
        result = qa_pipeline(prompt, max_new_tokens=200)[0]['generated_text']
        questions = [q.strip("-â€¢ \n") for q in result.split("\n") if len(q.strip()) > 8]
        all_questions.extend(questions)

    return all_questions

if uploaded_file:
    with st.spinner("ğŸ” Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰..."):
        ext = uploaded_file.name.split(".")[-1].lower()

        if ext == "pdf":
            content_text = extract_text_from_pdf(uploaded_file)
        elif ext in ["jpg", "png"]:
            content_text = extract_text_from_image(uploaded_file)
        else:
            content_text = "ØµÙŠØºØ© ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©."

        if content_text.strip():
            st.success("âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ù†Ø¬Ø§Ø­!")
            st.text_area("ğŸ“– Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:", content_text, height=200)

            if st.button("âœï¸ ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ø¦Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"):
                with st.spinner("âœï¸ Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©..."):
                    questions = generate_questions(content_text)
                    st.subheader("ğŸ“Œ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©:")

                    for idx, question in enumerate(questions, 1):
                        st.markdown(f"**{idx}. {question}**")

                    # Ø®ÙŠØ§Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙƒÙ…Ù„Ù Ù†ØµÙŠ
                    st.download_button(
                        label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙƒÙ…Ù„Ù Ù†ØµÙŠ",
                        data="\n".join(f"{i+1}. {q}" for i, q in enumerate(questions)),
                        file_name="generated_questions.txt",
                        mime="text/plain"
                    )
        else:
            st.error("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙŠ Ù†Øµ Ù…Ù† Ø§Ù„Ù…Ù„Ù.")
