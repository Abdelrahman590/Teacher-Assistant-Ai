# teacher_analyzer_app.py
import streamlit as st
import os
import tempfile
from transformers import pipeline
from PyPDF2 import PdfReader
import pytesseract
from PIL import Image
#import moviepy.editor as mp
import speech_recognition as sr
#import imageio_ffmpeg
#print(imageio_ffmpeg.get_ffmpeg_exe())


st.set_page_config(page_title="Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ù„Ù…Ø© Ø§Ù„Ø°ÙƒÙŠ", layout="centered")
st.title("ğŸ“š Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ù„Ù…Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©")

uploaded_file = st.file_uploader("ğŸ“ Ø­Ù…Ù‘Ù„ÙŠ Ù…Ù„Ù Ø§Ù„Ø¯Ø±Ø³ (PDF, ØµÙˆØ±Ø©, ÙÙŠØ¯ÙŠÙˆ)", type=["pdf", "jpg", "png", "mp4"])

# ---------- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ ----------
def extract_text_from_pdf(file):
    reader = PdfReader(file)
    return "\n".join(page.extract_text() for page in reader.pages if page.extract_text())

def extract_text_from_image(image_file):
    image = Image.open(image_file)
    return pytesseract.image_to_string(image, lang='ara')

#def extract_text_from_video(video_file):
    #with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
    #    tmp.write(video_file.read())
    #    tmp_path = tmp.name

    #clip = mp.VideoFileClip(tmp_path)
    #audio_path = tmp_path.replace(".mp4", ".wav")
    #clip.audio.write_audiofile(audio_path)

    #recognizer = sr.Recognizer()
    #with sr.AudioFile(audio_path) as source:
    #    audio = recognizer.record(source)
    #try:
    #    return recognizer.recognize_google(audio, language='ar')
    #except:
    #    return "Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…."

# ---------- ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ----------
def generate_questions(text):
    qa_pipeline = pipeline("text2text-generation", model="aubmindlab/aragpt2-base")
    prompt = f"Ø§Ø³Ø£Ù„ 3 Ø£Ø³Ø¦Ù„Ø© Ù„ÙÙ‡Ù… Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ:\n{text}"
    return qa_pipeline(prompt, max_new_tokens=150)[0]['generated_text']

if uploaded_file:
    with st.spinner("ğŸ” Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰..."):
        ext = uploaded_file.name.split(".")[-1].lower()

        if ext == "pdf":
            content_text = extract_text_from_pdf(uploaded_file)
        elif ext in ["jpg", "png"]:
            content_text = extract_text_from_image(uploaded_file)
        #elif ext == "mp4":
        #    content_text = extract_text_from_video(uploaded_file)
        else:
            content_text = "ØµÙŠØºØ© ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©."

        if content_text.strip():
            st.success("âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ù†Ø¬Ø§Ø­!")
            st.text_area("ğŸ“– Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:", content_text, height=200)

            if st.button("âœï¸ ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ø¦Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"):
                with st.spinner("âœï¸ Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©..."):
                    result = generate_questions(content_text[:600])  # Limit for processing
                    st.subheader("ğŸ“Œ Ø£Ø³Ø¦Ù„Ø© Ù…Ù‚ØªØ±Ø­Ø©:")
                    for q in result.split("\n"):
                        if q.strip():
                            st.markdown(f"- {q.strip()}")
        else:
            st.error("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙŠ Ù†Øµ Ù…Ù† Ø§Ù„Ù…Ù„Ù.")
